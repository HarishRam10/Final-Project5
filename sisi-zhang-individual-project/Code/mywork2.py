# -*- coding: utf-8 -*-
"""Sisi_nlp_ensemble_lr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YS7BAbRbjuuxdDXP7ceufEveL-FSjNZe

# Ensembling with different number of models
Before ensembling our models, we like to test it out on CoLA dataset to see the score change with the number of models increasing.  
We will comapre the score between single models with ensembling models(up to 6 models).
"""

from google.colab import drive
import sys

# Mount Google Drive
drive.mount('/content/drive')

"""We make predictions of CoLA's dev set with 2 electras, 1 xlnet, and 3 berts, total 6 models and add the lable of CoLA's dev set.

From Running Trainer.py, we get the score of each model as following:


1.   electra-1 : 0.6774
2.   electra-2 : 0.6631
3.   bert-3 : 0.5981
4.   bert-1 : 0.5955
5.   bert-2 : 0.5754
6.   xlnet : 0.4676

We are going to start from ensamble all 6 models then drop one with the lowest score still a single model.


"""

# Get the absolute path of the current folder
import pandas as pd

abspath_curr = '/content/drive/My Drive/NLP_Final_Exam/'
df = pd.read_excel(abspath_curr + 'cola.xlsx',header=0)

df.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression


X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), 
                                                    df['target'], test_size=0.20,random_state=20000) 
model = LogisticRegression(solver='liblinear', random_state=20000).fit(X_train, y_train)
pred = model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,pred))

from sklearn.metrics import matthews_corrcoef
mcc_6 = matthews_corrcoef(pred,y_test)
print(mcc_6)

df.drop('xlnet-0',axis=1,inplace=True)
df.drop('xlnet-1',axis=1,inplace=True)
df.head()

X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), 
                                                    df['target'], test_size=0.20,random_state=20000) 
model = LogisticRegression(solver='liblinear', random_state=20000).fit(X_train, y_train)
pred = model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,pred))

from sklearn.metrics import matthews_corrcoef
mcc_5 = matthews_corrcoef(pred,y_test)
print(mcc_5)

df.drop('bert2-0',axis=1,inplace=True)
df.drop('bert2-1',axis=1,inplace=True)
df.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression


X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), 
                                                    df['target'], test_size=0.20,random_state=20000) 
model = LogisticRegression(solver='liblinear', random_state=20000).fit(X_train, y_train)
pred = model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,pred))

from sklearn.metrics import matthews_corrcoef
mcc_4 = matthews_corrcoef(pred,y_test)
print(mcc_4)

df.drop('bert-0',axis=1,inplace=True)
df.drop('bert-1',axis=1,inplace=True)
df.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression


X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), 
                                                    df['target'], test_size=0.20,random_state=20000) 
model = LogisticRegression(solver='liblinear', random_state=20000).fit(X_train, y_train)
pred = model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,pred))

from sklearn.metrics import matthews_corrcoef
mcc_3 = matthews_corrcoef(pred,y_test)
print(mcc_3)

df.drop('bert3-0',axis=1,inplace=True)
df.drop('bert3-1',axis=1,inplace=True)
df.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression


X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), 
                                                    df['target'], test_size=0.20,random_state=20000) 
model = LogisticRegression(solver='liblinear', random_state=20000).fit(X_train, y_train)
pred = model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,pred))

from sklearn.metrics import matthews_corrcoef
mcc_2 = matthews_corrcoef(pred,y_test)
print(mcc_2)

df.drop('electra2-0',axis=1,inplace=True)
df.drop('electra2-1',axis=1,inplace=True)
df.head()

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression


X_train, X_test, y_train, y_test = train_test_split(df.drop('target',axis=1), 
                                                    df['target'], test_size=0.20,random_state=20000) 
model = LogisticRegression(solver='liblinear', random_state=20000).fit(X_train, y_train)
pred = model.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test,pred))

from sklearn.metrics import matthews_corrcoef
mcc_1 = matthews_corrcoef(pred,y_test)
print(mcc_1)

mcc_score = pd.DataFrame({'number_of_models': [1,2,3,4,5,6] ,
                         'mcc_scores': [mcc_1,mcc_2,mcc_3,mcc_4,mcc_5,mcc_6]})
print(mcc_score)

from matplotlib import pyplot as plt
plt.plot(mcc_score.number_of_models, mcc_score.mcc_scores,"-", color="c")
plt.plot(mcc_score.number_of_models, mcc_score.mcc_scores,".",marker="v",color="k")
plt.ylim(0.65, 0.75)
plt.ylabel("score")
plt.xlabel("number of model ensemble ")
plt.title("Score vs Number of model ensemble for CoLA")
plt.show()

